T·∫°o API ƒë√°nh gi√° ƒë·ªô ph√π h·ª£p CV v·ªõi tin tuy·ªÉn d·ª•ng
Input: FILE CV(PDF)
System: N·ªôi dung tin tuy·ªÉn d·ª•ng
Output: ƒê√°nh gi√° ƒë·ªô ph√π h·ª£p c·ªßa CV v·ªõi tin tuy·ªÉn d·ª•ng

G·ª£i √Ω:
B1: D·ª±ng API nh·∫≠n v√†o l√† 1 file CV.
B2: Chuy·ªÉn ƒë·ªïi PDF sang Text (Th∆∞ vi·ªán ƒë·ªçc PDF c·ªßa python)
B3: Ph√¢n t√≠ch c√°c ch·ªâ ti√™u ch√≠nh t·ª´ JD, tr·ªçng s·ªë cho t·ª´ng ch·ªâ ti√™u
B4: G·ª≠i n·ªôi dung CV, k√®m c√°c ch·ªâ ti√™u t·ª´ JD l√™n cho LLM
B5: Nh·∫≠n k·∫øt qu·∫£, hi·ªÉn th·ªã ƒë·ªô ph√π h·ª£p

Y√™u c·∫ßu:
t·∫°o 1 file d√πng chung l√† review_cv.py ƒë·ªÉ ƒë√°nh gi√° cv, t·∫°o 1 file l√† api.py d√πng FastAPI v√† 1 file l√† app.py d√πng Streamlist

trong api th√¨ cung c·∫•p 2 tham s·ªë l√† n·ªôi dung file, prompt system l√† tin tuy·ªÉn d·ª•ng mu·ªën review

tham kh·∫£o t∆∞∆°ng t·ª± ƒëo·∫°n code d∆∞·ªõi

gen_poetic.py

```
from openai import OpenAI

client = OpenAI(api_key="...")  # API key c·ªßa b·∫°n

def generate_luc_bat_poem_stream(topic: str):
    prompt = f"""
B·∫°n l√† m·ªôt nh√† th∆° hi·ªán ƒë·∫°i, h√£y vi·∫øt m·ªôt b√†i th∆° l·ª•c b√°t v·ªÅ ch·ªß ƒë·ªÅ sau:
'{topic}'
Lu·∫≠t th∆° l·ª•c b√°t:
- C√¢u 1: 6 ch·ªØ; c√¢u 2: 8 ch·ªØ
- V·∫ßn cu·ªëi c√¢u 1 v√† c√¢u 2 ph·∫£i b·∫±ng nhau
- C√¢u 3: 6 ch·ªØ; c√¢u 4: 8 ch·ªØ; c√¢u 4 v·∫ßn cu·ªëi b·∫±ng c√¢u 2
- V√† ti·∫øp t·ª•c theo th·ªÉ l·ª•c b√°t truy·ªÅn th·ªëng

Vi·∫øt t·ª´ng c√¢u th∆°, gi·ªØ ƒë√∫ng lu·∫≠t th∆° l·ª•c b√°t, th·ªÉ hi·ªán c·∫£m x√∫c s√¢u s·∫Øc.
B·∫Øt ƒë·∫ßu ngay b√†i th∆°.
H√£y tr·∫£ l·ªùi theo d·∫°ng streaming text.
"""

    # Streaming response
    with client.responses.stream(
        model="gpt-4.1",
        input=[{"role": "user", "content": prompt}],
    ) as stream:
        for event in stream:
            if event.type == "response.output_text.delta":
                yield event.delta
            elif event.type == "response.error":
                yield f"[ERROR]: {event.error}"
```

api.py

```
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from gen_poetic import generate_luc_bat_poem_stream
class TopicRequest(BaseModel):
    topic: str
app = FastAPI()
@app.post("/stream_poem")
def stream_poem(request: TopicRequest):
    def event_generator():
        for chunk in generate_luc_bat_poem_stream(request.topic):
            yield chunk
    return StreamingResponse(event_generator(), media_type="text/plain")
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("api:app", host="0.0.0.0", port=8000, reload=True)
```

app.py

```
import streamlit as st
import requests
st.title("üéâ Demo Vi·∫øt Th∆° L·ª•c B√°t Streaming")
topic = st.text_input("Nh·∫≠p ch·ªß ƒë·ªÅ th∆°:")
if st.button("Vi·∫øt th∆°"):
    if not topic.strip():
        st.warning("Vui l√≤ng nh·∫≠p ch·ªß ƒë·ªÅ!")
    else:
        st.markdown("**B√†i th∆° l·ª•c b√°t ƒëang ƒë∆∞·ª£c t·∫°o, vui l√≤ng ch·ªù...**")
        response = requests.post(
            "http://localhost:8000/stream_poem",
            json={"topic": topic},
            stream=True
        )
        poem_display = st.empty()
        poem_text = ""
        # X·ª≠ l√Ω stream t·ª´ng chunk v√† hi·ªÉn th·ªã li√™n t·ª•c
        for chunk in response.iter_content(chunk_size=32):
            text = chunk.decode('utf-8')
            poem_text += text
            poem_display.text(poem_text)
```
